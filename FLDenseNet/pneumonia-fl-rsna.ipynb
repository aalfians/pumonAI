{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils import Sequence\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix, f1_score\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "VERDICT = ['NORMAL', 'PNEUMONIA']\n",
    "EPOCHS = 9\n",
    "BATCH_SIZE = 16\n",
    "ROOT_PATH = \"../rsna-pneumonia-detection-challenge/stage_2_train_images/\"\n",
    "\n",
    "DATA_SPLIT = 'DIFF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.array(self.x[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        batch_y = np.array(self.y[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../rsna-pneumonia-detection-challenge/stage_2_train_labels.csv')\n",
    "labels2 = pd.read_csv('../rsna-pneumonia-detection-challenge/stage_2_detailed_class_info.csv')\n",
    "\n",
    "combine = pd.merge(labels, labels2, how='inner', on=['patientId'])\n",
    "combine = combine.drop_duplicates(\"patientId\")\n",
    "combine = combine[combine['class'] != 'No Lung Opacity / Not Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for patient in combine['patientId']: \n",
    "    dcm_path = ROOT_PATH + patient + '.dcm'\n",
    "    dcm = dicom.dcmread(dcm_path).pixel_array\n",
    "    class_num = combine['Target'].loc[combine['patientId'] == patient].values[0]\n",
    "\n",
    "    resized_arr = cv2.resize(dcm, (IMG_SIZE, IMG_SIZE)) # Reshaping images to preferred size\n",
    "    resized_arr = np.stack((resized_arr,)*3, axis=-1)\n",
    "    resized_arr = preprocess_input(resized_arr.astype(np.float32))\n",
    "    x_data.append(resized_arr)\n",
    "    y_data.append(class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data, test_size=0.20)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, stratify=y_test, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClsModel(n_classes=1):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "    x = layers.AveragePooling2D(pool_size=(3,3), name='avg_pool')(base_model.output)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', name='dense_post_pool')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='sigmoid', name='predictions')(x)\n",
    "    model = keras.Model(inputs=base_model.input, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClsModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(x_train, y_train, BATCH_SIZE)\n",
    "val_gen = DataGenerator(x_val, y_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self):\n",
    "        self.history = dict()\n",
    "        self.history['loss'] = []\n",
    "        self.history['accucary'] = []\n",
    "        self.history['val_loss'] = []\n",
    "        self.history['val_accuracy'] = []\n",
    "        self.history['test_f1_score'] = []\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        r = model.fit(train_gen, epochs=1, batch_size=BATCH_SIZE, validation_data = val_gen, steps_per_epoch=np.ceil(len(y_train)/BATCH_SIZE))\n",
    "        \n",
    "        self.history['loss'].append(r.history['loss'][0])\n",
    "        self.history['accucary'].append(r.history['accuracy'][0])\n",
    "        self.history['val_loss'].append(r.history['val_loss'][0])\n",
    "        self.history['val_accuracy'].append(r.history['val_accuracy'][0])\n",
    "\n",
    "        print(\"Fit history: \", r.history)\n",
    "        return model.get_weights(), len(x_train), {\"accuracy\": float(r.history['accuracy'][0]), \"loss\": float(r.history['loss'][0]), \"val_accuracy\": float(r.history['val_accuracy'][0]), \"val_loss\": float(r.history['val_loss'][0])}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        loss, _ = model.evaluate(x_test, y_test)\n",
    "\n",
    "        predictions = model.predict(x_test, steps = np.ceil(len(y_test)/BATCH_SIZE))\n",
    "        predictions = np.where(predictions > 0.5, 1, 0)\n",
    "        predictions = predictions.flatten()\n",
    "\n",
    "        epoch_f1_score = f1_score(y_test, predictions, average='weighted')\n",
    "        self.history['test_f1_score'].append(epoch_f1_score)\n",
    "\n",
    "        print(\"Test F1 Score: \", epoch_f1_score)\n",
    "        return loss, len(x_test), {\"f1_score\": float(epoch_f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FlowerClient()\n",
    "\n",
    "history = fl.client.start_numpy_client(\n",
    "    server_address=\"10.30.200.41:5002\",\n",
    "    client=client,\n",
    "    grpc_max_message_length=1024*1024*1024,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,EPOCHS+1)]\n",
    "fig , ax = plt.subplots(1,3)\n",
    "train_acc = client.history['accucary']\n",
    "train_loss = client.history['loss']\n",
    "val_acc = client.history['val_accuracy']\n",
    "val_loss = client.history['val_loss']\n",
    "test_f1_score = client.history['test_f1_score']\n",
    "fig.set_size_inches(30,5)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "\n",
    "ax[2].plot(epochs , test_f1_score , 'g-o' , label = 'F1 Score')\n",
    "ax[2].set_title('Predictions F1 Score')\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel(\"Epochs\")\n",
    "ax[2].set_ylabel(\"F1 Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = np.where(predictions > 0.5, 1, 0)\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "# predictions = predictions.reshape(1,-1)[0]\n",
    "predictions[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(client.history)\n",
    "df.to_csv('./every-split-data-metrics/' + DATA_SPLIT + '-batch-1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names = ['Normal (Class 0)','Pneumonia (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = VERDICT, yticklabels = VERDICT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
